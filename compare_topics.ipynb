{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data\n",
    "- df1 = human data\n",
    "- df2 = synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls = pd.ExcelFile('FinalTopicAnnotations_shareable.xlsx')\n",
    "df1 = pd.read_excel(xls, 'top words')#human data topics\n",
    "df2 = pd.read_excel(xls, 'synthetic_fullword')#synthetic topics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We manually group together the topics into the topics in UMD-ODH\n",
    "Left side = human Right side = synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_dict = {\n",
    "    'family': ([2], [18]),\n",
    "    'work':([5,17], [3, 24]),\n",
    "    'health':([1, 3], [4]),\n",
    "    'finance':([22], [6]),\n",
    "    'relationship':([10, 19], [21]),\n",
    "    'school':([11, 13], [12]),\n",
    "    'news and social media':([7], [11, 17]),\n",
    "    'unemployment':([17], [6]),\n",
    "    'stress': ([0], [10])\n",
    "}\n",
    "\n",
    "topic_words = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the tokens for each overarching groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "family ([2], [18])\n",
      "work ([5, 17], [3, 24])\n",
      "health ([1, 3], [4])\n",
      "finance ([22], [6])\n",
      "relationship ([10, 19], [21])\n",
      "school ([11, 13], [12])\n",
      "news and social media ([7], [11, 17])\n",
      "unemployment ([17], [6])\n",
      "stress ([0], [10])\n"
     ]
    }
   ],
   "source": [
    "df1_vocab = {}\n",
    "df2_vocab = {}\n",
    "\n",
    "for k, v in topic_dict.items():\n",
    "    df1_topics = df1.iloc[v[0], :]['words'].values.sum().replace(' ', '').split(',')\n",
    "    df2_topics = df2.iloc[v[1], :]['words'].values.sum().replace(' ', '').split(',')\n",
    "    if k not in df1_vocab:\n",
    "        df1_vocab[k] = []\n",
    "        df2_vocab[k] = []\n",
    "    df1_vocab[k] = df1_topics\n",
    "    df2_vocab[k] = df2_topics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Glove model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.09240163"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "embeddings = {}\n",
    "with open(\"../../../../local/glove.6B.300d.txt\", \"r\", encoding=\"utf-8\") as file_p:\n",
    "    for line in tqdm(file_p):\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = torch.Tensor(np.asarray(values[1:], \"float32\"))\n",
    "        embeddings[word] = vector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity of topics\n",
    "Obtaining the avg. cosine similarity by taking the mean of the embeddings for human and synthetic topics and calculating the cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic: family  score  tensor(0.7889)\n",
      "topic: work  score  tensor(0.9010)\n",
      "topic: health  score  tensor(0.8567)\n",
      "topic: finance  score  tensor(0.9352)\n",
      "topic: relationship  score  tensor(0.9233)\n",
      "topic: school  score  tensor(0.9070)\n",
      "topic: news and social media  score  tensor(0.8434)\n",
      "topic: unemployment  score  tensor(0.8780)\n",
      "topic: stress  score  tensor(0.8848)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for k in topic_dict.keys():\n",
    "    # print(k)\n",
    "    human = df1_vocab[k]        \n",
    "    synth = df2_vocab[k]\n",
    "    synth_embs = [\n",
    "        x for x in [embeddings.get(token) for token in synth] if x is not None\n",
    "    ]\n",
    "    human_embs = [\n",
    "        x for x in [embeddings.get(token) for token in human] if x is not None\n",
    "    ]\n",
    "\n",
    "    synth_embs = torch.stack(synth_embs)\n",
    "    human_embs = torch.stack(human_embs)\n",
    "\n",
    "    synth_mean = synth_embs.mean(dim=0)\n",
    "    human_mean = human_embs.mean(dim=0)\n",
    "\n",
    "    sim_score = F.cosine_similarity(synth_mean, human_mean, dim=0)\n",
    "\n",
    "    print('topic:', k, ' score ', sim_score)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the baseline by finding the avg cosine similarity for a random pair of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75299853"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rands = []\n",
    "for i in range(100):\n",
    "    rand_words1 = random.sample(list(embeddings.keys()), k=30)\n",
    "    rand_words2 = random.sample(list(embeddings.keys()), k=30)\n",
    "\n",
    "    rand_embs1 = torch.stack([embeddings.get(tok) for tok in rand_words1])\n",
    "    rand_embs2 = torch.stack([embeddings.get(tok) for tok in rand_words2])\n",
    "\n",
    "    rand_mean1 = rand_embs1.mean(dim=0)\n",
    "    rand_mean2 = rand_embs2.mean(dim=0)\n",
    "\n",
    "    sim_score = F.cosine_similarity(rand_mean1, rand_mean2, dim=0)\n",
    "    rands.append(sim_score)\n",
    "\n",
    "print(np.mean(rands))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
