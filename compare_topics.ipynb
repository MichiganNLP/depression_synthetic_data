{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls = pd.ExcelFile('FinalTopicAnnotations_shareable.xlsx')\n",
    "df1 = pd.read_excel(xls, 'top words')#human data topics\n",
    "df2 = pd.read_excel(xls, 'synthetic_fullword')#synthetic topics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We manually group together the topics into the topics in UMD-ODH\n",
    "Left side = human Right side = synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_dict = {\n",
    "    'family': ([2], [18]),\n",
    "    'work':([5,17], [3, 24]),\n",
    "    'health':([1, 3], [4]),\n",
    "    'finance':([22], [6]),\n",
    "    'relationship':([10, 19], [21]),\n",
    "    'school':([11, 13], [12]),\n",
    "    'news and social media':([7], [11, 17]),\n",
    "    'unemployment':([17], [6]),\n",
    "    'stress': ([0], [10])\n",
    "}\n",
    "\n",
    "topic_words = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "skipped2 = {k:0 for k in topic_dict.keys()}#maps topics to cosine scores\n",
    "for k, v in topic_dict.items():\n",
    "    for w2 in comp2:#for each word in synthetic\n",
    "        if w2 in glove_vectors:\n",
    "            score.append(glove_vectors.similarity(w1, w2))#calculate similarity and log\n",
    "        else:\n",
    "            skipped2[k] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'family': 1,\n",
       " 'work': 1,\n",
       " 'health': 1,\n",
       " 'finance': 1,\n",
       " 'relationship': 1,\n",
       " 'school': 1,\n",
       " 'news and social media': 1,\n",
       " 'unemployment': 1,\n",
       " 'stress': 1}"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skipped2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'family': 0.41239268,\n",
       " 'work': 0.46935058,\n",
       " 'health': 0.4298631,\n",
       " 'finance': 0.55569744,\n",
       " 'relationship': 0.47863868,\n",
       " 'school': 0.51698375,\n",
       " 'news and social media': 0.3623336,\n",
       " 'unemployment': 0.51615554,\n",
       " 'stress': 0.47469574}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 18\n",
      "5 3\n",
      "5 24\n",
      "17 3\n",
      "17 24\n",
      "1 4\n",
      "3 4\n",
      "22 6\n",
      "10 21\n",
      "19 21\n",
      "11 12\n",
      "13 12\n",
      "7 11\n",
      "7 17\n",
      "17 6\n",
      "0 10\n"
     ]
    }
   ],
   "source": [
    "topic_score = {k:0 for k in topic_dict.keys()}\n",
    "for k, v in topic_dict.items():\n",
    "    score = []\n",
    "    for f1 in v[0]:\n",
    "        for f2 in v[1]:\n",
    "            print(f1, f2)\n",
    "            score.append(glove_vectors.similarity(f1, f2))\n",
    "    topic_score[k] = np.array(score).mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'family': 0.6426054,\n",
       " 'work': 0.56419694,\n",
       " 'health': 0.75654554,\n",
       " 'finance': 0.3989596,\n",
       " 'relationship': 0.5884793,\n",
       " 'school': 0.56665945,\n",
       " 'news and social media': 0.6217948,\n",
       " 'unemployment': 0.5620796,\n",
       " 'stress': 0.6721222}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_neg_words = {i:df1.iloc[i, :]['words'].replace(' ', '').split(',') for i in df1_neg}\n",
    "df2_neg_words = {i:df2.iloc[i, :]['words'].replace(' ', '').split(',') for i in df2_neg}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for each word in df:\n",
    "    compare to each of df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting\n",
      "house\n",
      "dealt\n",
      "moving\n",
      "daily\n",
      "things\n",
      "needs\n",
      "week\n",
      "apartment\n",
      "pretty\n",
      "everyday\n",
      "water\n",
      "housing\n",
      "room\n",
      "starting\n",
      "motivation\n",
      "worried\n",
      "basic\n",
      "hard\n",
      "plan\n",
      "small\n",
      "look\n",
      "order\n",
      "broke\n",
      "research\n",
      "energy\n",
      "talked\n",
      "accomplish\n",
      "away\n",
      "right\n",
      "trying\n",
      "financial\n",
      "pandemic\n",
      "situation\n",
      "find\n",
      "music\n",
      "income\n",
      "car\n",
      "best\n",
      "current\n",
      "paying\n",
      "budget\n",
      "medical\n",
      "virus\n",
      "safe\n",
      "stay\n",
      "listening\n",
      "debt\n",
      "meet\n",
      "corona\n",
      "mother\n",
      "listen\n",
      "playing\n",
      "saving\n",
      "calm\n",
      "stressor\n",
      "paid\n",
      "games\n",
      "reduced\n",
      "roommate\n",
      "covid\n",
      "husband\n",
      "issues\n",
      "health\n",
      "19\n",
      "doctor\n",
      "loved\n",
      "eating\n",
      "ones\n",
      "child\n",
      "pain\n",
      "meds\n",
      "doctors\n",
      "state\n",
      "problems\n",
      "comes\n",
      "member\n",
      "disorder\n",
      "insurance\n",
      "contracting\n",
      "able\n",
      "scared\n",
      "afford\n",
      "alot\n",
      "currently\n",
      "precautions\n",
      "called\n",
      "behavior\n",
      "tooth\n",
      "travel\n",
      "having\n",
      "taking\n",
      "stressful\n",
      "care\n",
      "kids\n",
      "keeping\n",
      "way\n",
      "classes\n",
      "staying\n",
      "future\n",
      "healthy\n",
      "uncertainty\n",
      "ahead\n",
      "general\n",
      "usual\n",
      "pandemic\n",
      "catch\n",
      "improve\n",
      "regular\n",
      "returning\n",
      "dog\n",
      "need\n",
      "sources\n",
      "away\n",
      "effective\n",
      "eat\n",
      "results\n",
      "current\n",
      "course\n",
      "ill\n",
      "stress\n",
      "biggest\n",
      "source\n",
      "life\n",
      "deal\n",
      "moment\n",
      "right\n",
      "weight\n",
      "able\n",
      "christmas\n",
      "yoga\n",
      "currently\n",
      "run\n",
      "live\n",
      "causing\n",
      "helped\n",
      "cause\n",
      "lose\n",
      "marijuana\n",
      "exercising\n",
      "makes\n",
      "exactly\n",
      "applications\n",
      "upcoming\n",
      "smoking\n",
      "season\n",
      "lately\n",
      "diet\n",
      "place\n",
      "gaining\n",
      "problems\n",
      "friends\n",
      "program\n",
      "plans\n",
      "dissertation\n",
      "applying\n",
      "know\n",
      "seeking\n",
      "jobs\n",
      "deal\n",
      "college\n",
      "apply\n",
      "kind\n",
      "looking\n",
      "cancelled\n",
      "planner\n",
      "hope\n",
      "making\n",
      "preparing\n",
      "continued\n",
      "system\n",
      "coming\n",
      "want\n",
      "trying\n",
      "teaching\n",
      "advice\n",
      "face\n",
      "position\n",
      "case\n",
      "projects\n",
      "school\n",
      "schedule\n",
      "study\n",
      "trying\n",
      "assignments\n",
      "organized\n",
      "studying\n",
      "class\n",
      "things\n",
      "tried\n",
      "finals\n",
      "breaks\n",
      "graduate\n",
      "semester\n",
      "stay\n",
      "exams\n",
      "anxiety\n",
      "college\n",
      "final\n",
      "week\n",
      "managing\n",
      "taken\n",
      "stressing\n",
      "exam\n",
      "prepared\n",
      "hope\n",
      "organize\n",
      "coming\n",
      "smoke\n",
      "deadlines\n",
      "try\n",
      "talk\n",
      "sure\n",
      "things\n",
      "friends\n",
      "concern\n",
      "worry\n",
      "worrying\n",
      "bit\n",
      "country\n",
      "finishing\n",
      "able\n",
      "son\n",
      "making\n",
      "plan\n",
      "focused\n",
      "routine\n",
      "helps\n",
      "know\n",
      "think\n",
      "big\n",
      "tried\n",
      "crisis\n",
      "buy\n",
      "father\n",
      "distract\n",
      "forget\n",
      "need\n",
      "working\n",
      "best\n",
      "home\n",
      "finances\n",
      "started\n",
      "busy\n",
      "cope\n",
      "possible\n",
      "stay\n",
      "covid-19\n",
      "long\n",
      "soon\n",
      "coronavirus\n",
      "anxiety\n",
      "things\n",
      "internship\n",
      "stuck\n",
      "working\n",
      "staying\n",
      "second\n",
      "spend\n",
      "baby\n",
      "month\n",
      "job\n",
      "previous\n",
      "trying\n",
      "ago\n",
      "stayed\n",
      "disability\n",
      "fact\n",
      "stressors\n",
      "thinking\n",
      "time\n",
      "little\n",
      "spending\n",
      "children\n",
      "vacation\n",
      "complete\n",
      "schoolwork\n",
      "week\n",
      "set\n",
      "working\n",
      "rest\n",
      "marriage\n",
      "activities\n",
      "counseling\n",
      "cleaning\n",
      "practice\n",
      "tasks\n",
      "sad\n",
      "tests\n",
      "grandma\n",
      "step\n",
      "management\n",
      "daily\n",
      "stroke\n",
      "spend\n",
      "exercising\n",
      "possible\n",
      "schedule\n",
      "appointments\n",
      "dealing\n",
      "talking\n",
      "good\n",
      "walks\n",
      "sleeping\n",
      "girlfriend\n",
      "friends\n",
      "struggling\n",
      "currently\n",
      "honestly\n",
      "treatment\n",
      "lot\n",
      "thing\n",
      "starting\n",
      "best\n",
      "grandmother\n",
      "team\n",
      "college\n",
      "changed\n",
      "exercising\n",
      "changes\n",
      "pregnant\n",
      "know\n",
      "parents\n",
      "recently\n",
      "prepared\n",
      "recovery\n",
      "toddler\n",
      "long\n",
      "certain\n",
      "depression\n",
      "therapist\n",
      "loss\n",
      "friends\n",
      "talked\n",
      "medication\n",
      "weight\n",
      "cancer\n",
      "broke\n",
      "isolation\n",
      "lot\n",
      "eat\n",
      "support\n",
      "exercise\n",
      "probably\n",
      "father\n",
      "fear\n",
      "going\n",
      "leave\n",
      "loneliness\n",
      "seeing\n",
      "wo\n",
      "difficult\n",
      "unable\n",
      "starting\n",
      "friend\n",
      "pass\n",
      "things\n",
      "important\n",
      "chronic\n",
      "different\n",
      "relax\n",
      "summer\n",
      "unemployed\n",
      "ask\n",
      "lot\n",
      "patient\n",
      "wedding\n",
      "trying\n",
      "pray\n",
      "let\n",
      "play\n",
      "planning\n",
      "parenting\n",
      "support\n",
      "helping\n",
      "rent\n",
      "continue\n",
      "things\n",
      "economy\n",
      "leave\n",
      "relaxed\n",
      "spoken\n",
      "single\n",
      "gym\n",
      "night\n",
      "stressing\n",
      "open\n",
      "find\n",
      "black\n",
      "living\n",
      "trying\n",
      "things\n",
      "unemployment\n",
      "end\n",
      "ready\n",
      "working\n",
      "know\n",
      "recently\n",
      "pandemic\n",
      "able\n",
      "tried\n",
      "contract\n",
      "suicide\n",
      "far\n",
      "reached\n",
      "means\n",
      "school\n",
      "week\n",
      "counter\n",
      "normalcy\n",
      "stressors\n",
      "need\n",
      "met\n",
      "lot\n",
      "try\n",
      "difficult\n",
      "exercise\n",
      "possible\n",
      "long\n"
     ]
    }
   ],
   "source": [
    "for d in df1_neg_words:\n",
    "    # print(d)\n",
    "    for dd in d:\n",
    "        print(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df1_neg_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_488065/517703811.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpair_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf1_neg_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdd1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdd1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglove_vectors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df1_neg_words' is not defined"
     ]
    }
   ],
   "source": [
    "pair_score = {}\n",
    "for i1, d1 in df1_neg_words.items():\n",
    "    score = []\n",
    "    for dd1 in d1:\n",
    "        if dd1 in glove_vectors:\n",
    "            for i2, d2 in df2_neg_words.items():\n",
    "                for dd2 in d2:\n",
    "                    if dd2 in glove_vectors:\n",
    "                        score.append(glove_vectors.similarity(dd1, dd2))\n",
    "                if np.array(score).mean() > 0.5:\n",
    "                    pair_score[(i1, i2)] = np.array(score).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5435685"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors.similarity('work', 'deadline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.09240163"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "embeddings = {}\n",
    "with open(\"../../../../local/glove.6B.300d.txt\", \"r\", encoding=\"utf-8\") as file_p:\n",
    "    for line in tqdm(file_p):\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = torch.Tensor(np.asarray(values[1:], \"float32\"))\n",
    "        embeddings[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic: family  score  tensor(0.7889)\n",
      "topic: work  score  tensor(0.9010)\n",
      "topic: health  score  tensor(0.8567)\n",
      "topic: finance  score  tensor(0.9352)\n",
      "topic: relationship  score  tensor(0.9233)\n",
      "topic: school  score  tensor(0.9070)\n",
      "topic: news and social media  score  tensor(0.8434)\n",
      "topic: unemployment  score  tensor(0.8780)\n",
      "topic: stress  score  tensor(0.8848)\n"
     ]
    }
   ],
   "source": [
    "rands = []\n",
    "for k in topic_dict.keys():\n",
    "    # print(k)\n",
    "    human = df1_vocab[k]        \n",
    "    synth = df2_vocab[k]\n",
    "    synth_embs = [\n",
    "        x for x in [embeddings.get(token) for token in synth] if x is not None\n",
    "    ]\n",
    "    human_embs = [\n",
    "        x for x in [embeddings.get(token) for token in human] if x is not None\n",
    "    ]\n",
    "\n",
    "    synth_embs = torch.stack(synth_embs)\n",
    "    human_embs = torch.stack(human_embs)\n",
    "\n",
    "    synth_mean = synth_embs.mean(dim=0)\n",
    "    human_mean = human_embs.mean(dim=0)\n",
    "\n",
    "    sim_score = F.cosine_similarity(synth_mean, human_mean, dim=0)\n",
    "\n",
    "    # print(f\"Sim_score: {sim_score}\")\n",
    "    print('topic:', k, ' score ', sim_score)\n",
    "\n",
    "    \n",
    "    rand_words1 = random.sample(list(embeddings.keys()), k=30)\n",
    "    rand_words2 = random.sample(list(embeddings.keys()), k=30)\n",
    "\n",
    "    rand_embs1 = torch.stack([embeddings.get(tok) for tok in rand_words1])\n",
    "    rand_embs2 = torch.stack([embeddings.get(tok) for tok in rand_words2])\n",
    "\n",
    "    rand_mean1 = rand_embs1.mean(dim=0)\n",
    "    rand_mean2 = rand_embs2.mean(dim=0)\n",
    "\n",
    "    sim_score = F.cosine_similarity(rand_mean1, rand_mean2, dim=0)\n",
    "    rands.append(sim_score)\n",
    "    # breakpoint()\n",
    "\n",
    "    # print(\"exiting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75299853"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
